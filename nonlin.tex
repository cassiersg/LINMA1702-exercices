\section{Optimisation non-linéaire: Gradient et gradients conjugués}

\begin{enumerate}

    \begin{solution}
    \end{solution}

  \item Soit la fonction $f(x_1, x_2)= 2 x_1^3+3 x_1^2+12x_1 x_2 + 3 x_2^2
    -6 x_2 + 54$. Trouvez les points stationnaires de cette fonction et déterminez leur nature.
    La fonction possède-t-elle un minimum global? un maximum global?

    \begin{solution}
    \end{solution}

  \item Trouvez les points maximants et les points minimants de la fonction $f(x_1, x_2)=2x_1^2+x_2^2-2x_1x_2+2x_1^3+x_1^4$.

    \begin{solution}
    \end{solution}

  \item Trouvez si possible une fonction $f$ de deux variables et un point stationnaire $x_*$ de $f$ qui maximise $f$ et pour lequel
    $\nabla^2 f(x_*)
    \geq 0$. Même question pour  $\nabla^2 f(x_*)> 0$

    \begin{solution}
    \end{solution}

  \item Considérez la fonction quadratique $f(x)=(1/2) x^T Q x-c^T x$ avec $Q$ symétrique. Sous quelle condition cette fonction possède-t-elle un
    point stationnaire? un minimum local? un point stationnaire mais pas de minimum ni de maximum local?

    \begin{solution}
    \end{solution}

  \item Soit $f(x_1, x_2)=2x_1^2+x_1 \sin x_2$ la direction $(-2, 3)$ est-elle une direction de descente pour $f$ en $(2, -1)$? Si oui, donnez
    une expression pour le point résultant de la minimisation de la fonction dans cette direction.


    \begin{solution}
    \end{solution}

  \item On d\'esire minimiser la fonction:

    $$
    f(x_1, x_2)=2x_1^2 + x_2^2 - 2xy + 2x_1^3 + x_1^4
    $$

    par une methode it\'erative. Celle-ci nous am\`ene \`a minimiser
    la fonction objectif le long de la direction $d = (-1, 4)^T$ au
    d\'epart du point $x=(2,-1)^T$. La direction $d$ est-elle une
    direction de descente? Utilisez la condition d'Armijo pour trouver
    un nouveau point de d\'epart.


%SOLUTION:
%
%gradient = $(66, -6)$ donc descente. Il faut minimiser
%$f(2-\alpha, -1+ 4* \alpha)$. Avec $\epsilon=0.1$ (donc Armijo est
%$f(x+ \alpha*d) \leq 45 - 9*\alpha$) et $\eta=2$, $\alpha=1$
%convient.


    \begin{solution}
    \end{solution}

  \item Soit la fonction $f(x,y)=x^2+y^2(x^4-5x^2+7)$. Lors d'une
    tentative de minimisation de cette fonction, on utilise un
    algorithme qui essaie successivement comme directions de descente
    les axes $x$ et $y$.
    \begin{enumerate}
      \item Considérant une descente suivant l'axe $x$ à partir du point
        $(2,2)$, déterminez le sens de descente (augmentation ou
        diminution de $x$). Justifiez.
      \item Ayant obtenu la direction de
        descente $d_k$ au point précédent, on définit la fonction
        $F(\alpha)=f(x_k-\alpha d_k)$. Utilisez le critère d'Armijo pour
        effectuer une minimisation approximative de la fonction
        $F(\alpha)$. Donnez le $\alpha$ obtenu, ainsi que les coordonnées
        du point atteint.
      \item Appliquez maintenant la méthode en utilisant
        la direction $y$ à partir du nouveau point obtenu.
    \end{enumerate}

%%Réponse:
%%\begin{enumerate}
%%\item Direction : $(-1,0)$, car $\nabla f (2,2) = (52,12)$.
%%\item $F(\alpha)=f(2-\alpha,2)=4(2-\alpha)^4-19(2-\alpha)^2+28$.
%%\newline $F(0)=16$, $F'(0)=-52$
%%\newline Critère d'Armijo, avec $\varepsilon=1$ : $F(\alpha)\leq 16-5.2 \alpha$
%%\newline Essai avec $\alpha=1$ ok, $\alpha=2$ non. Donc
%%$\alpha=1$.
%%\newline Point atteint : (1,2)
%%\item $F(\alpha)\leq 13-1.2 \alpha$, $\alpha=2$, (1,0)
%%\newline puis en $x$, $F(\alpha)\leq 1-0.2 \alpha$, $\alpha=1$, (0,0).





    \begin{solution}
    \end{solution}

  \item Soit $f(x_1, x_2)=2x_1^2 + x_2^2 -2 x_1 x_2 + 2 x_1^3 + x_1^4$. La direction $(0, 1)$ est-elle une direction de descente pour $f$ en
    $(0, -2)$? Trouvez l'ensemble des directions de descente en ce point. Quelle est la direction de plus grande pente?

    \begin{solution}
    \end{solution}

  \item Soit $f$ une fonction dont on cherche un minimum au moyen d'un algorithme qui effectue des minimisations unidimensionnelles exactes.
    Démontrez qu'une direction de recherche $d_k$ est toujours orthogonale au gradient de la fonction au nouveau point $x_{k+1}$.

    \begin{solution}
    \end{solution}

  \item Soit la fonction quadratique $f(x)=(1/2) x^T Q x-c^T x$ avec $Q=diag(1, \gamma, \gamma^2)$ et $c=(1, 1, 1)^T$. On cherche un minimum
    de $f$ au moyen de la méthode de la plus grande pente au départ de l'origine. Pouvez-vous borner le nombre d'itérations en fonction de la
    précision souhaitée?

    \begin{solution}
    \end{solution}

  \item La méthode de la plus grande pente est appliquée au problème de la minimisation de $f(x_1, x_2)=x_1^2 + 2 x_2^2$ au départ de $(2, 1)$.
    Montrez que les approximations successives sont données par $x_k =  (2, (-1)^k)/3^k$. Montrez que $f(x_{k+1})=f(x_k)/9$.


    \begin{solution}
    \end{solution}

  \item  La fonction de Rosenbrock est la fonction

    $$f(x_1,x_2) = (x_1-1)^2 + \lambda({x_1}^2-x_2)^2$$

    pour $\lambda \in \R$.\\



    a) Trouvez les points stationnaires de $f$ et discutez leur nature en fonction de $\lambda$.\\

    b) La méthode de la plus grande pente est utilisée pour trouver un point minimant de $f$ au départ de $(0, 0)$.
    Combien d'itérations faut-il dans le cas $\lambda = 0$? Caractérisez la vitesse de convergence de la
    méthode dans le cas $\lambda >0$. Si possible, quantifiez votre réponse pour le cas  $\lambda =10$.

    \begin{solution}
    \end{solution}

  \item  Consid\'erons la fonction

    $$f(x_1,x_2) = 5 x_1^2 + 3 x_1 x_2 + 5 x_2^2 - 6 x_1 -8 x_2$$




    a) Trouvez les points stationnaires de $f$ et discutez leur nature.

    b) La m\'ethode de la plus grande pente est utilis\'ee pour trouver un point
    minimant de $f$ au d\'epart de $(0, 0)$.
    Caract\'erisez la vitesse de convergence de la
    m\'ethode. Si possible, quantifiez votre r\'eponse.



\end{enumerate}

\newpage


\section{Optimisation non-linéaire: Newton et quasi-Newton}

\begin{enumerate}



    \begin{solution}
    \end{solution}

  \item Utilisez la méthode de Newton pour trouver un point minimant de $f(x_1, x_2)=5x_1^4+6x_2^4-6x_1^2+2 x_1 x_2 +5x_2^2+15x_1-7x_2+13$.
    Partez de $x_0=(1, 1)$.

    \begin{solution}
    \end{solution}

  \item Utilisez la méthode de Newton modifiée (avec une recherche unidimensionnelle) pour la résolution de
    $$\min 2x_1^2 + x_2^2-2x_1 x_2 + 2 x_1^3 + x_1^4$$
    Effectuez seulement les deux premières
    itérations et partez de $x_0=(2, -1)$.



    \begin{solution}
    \end{solution}

  \item Appliquez la méthode de quasi-Newton de rang un à la résolution de

    $$\min \frac{1}{2} x^TAx-b^Tx$$ pour

  $$A=\left( \begin{array}{rrr} 5 & 2& 1 \\ 2 & 7 & 3 \\ 1 & 3 & 9 \end{array} \right) \quad  b= \left( \begin{array}{c} -9 \\ 0 \\8
    \end{array} \right).$$

    Initialisez la méthode avec $x_0= (0, 0, 0)$ et $H_0 = I$.



    \begin{solution}
    \end{solution}

  \item  Démontrez qu'avec la méthode Davidon-Fletcher-Powell tout  choix
    de $\alpha_k>0$ pour lequel $p_k^T q_k >0$ est tel que $H_{k+1}$ est définie positive lorsque $H_k$ l'est. Montrez que cette propriété est bien
    satisfaite lorsque $\alpha_k$ est le point minimant de $F(\alpha)=f(x_k+ \alpha d_k)$. Vous pouvez utiliser le fait que toute matrice
    symétrique et définie positive $A$ possède une racine carrée $B$ symétrique et définie positive, $A= B B$ avec $B$ symétrique et
    définie positive.

    \begin{solution}
    \end{solution}

  \item Nous considérons la méthode DFP. Supposons que la fonction $F(\alpha)= f(x_k+ \alpha d_k)$  possède unique minimum $\alpha'$ et est
    dérivable pour
    $\alpha >0$. Démontrez que tout choix de $\alpha_k > \alpha'$ pour $x_{k+1}=x_k + \alpha_k d_k$ est tel que
    $p_k^T q_k >0$.

    \begin{solution}
    \end{solution}

\end{enumerate}
